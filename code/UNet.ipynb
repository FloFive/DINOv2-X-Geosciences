{"cells":[{"cell_type":"markdown","metadata":{"id":"Eea7gOXnPViA"},"source":["#**Libraries / path definition / various functions**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ruIa6hvUB_kH"},"outputs":[],"source":["!pip install torchmetrics"]},{"cell_type":"markdown","source":["Libraries"],"metadata":{"id":"8Fy4IzKr4BFm"}},{"cell_type":"code","source":["import os\n","import sys\n","import random\n","import numpy as np\n","from tqdm import tqdm\n","import cv2\n","import matplotlib.pyplot as plt\n","from datetime import datetime\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","from torch.utils.data import DataLoader, random_split\n","import torchvision\n","from torchvision import datasets, transforms\n","from torchvision.datasets import VisionDataset\n","import torchvision.transforms.functional as Fv\n","import torchmetrics\n","from torchmetrics import JaccardIndex\n","from transformers import get_scheduler"],"metadata":{"id":"WXsTWw_oDgko"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Some path to adapt accordingly"],"metadata":{"id":"czf69uxW5GKv"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","project_dir = '/content/gdrive/MyDrive/Schism/'\n","sys.path.append(os.path.join(project_dir, \"code/DinoV2/\"))\n","\n","# Define the project directory path\n","#project_dir = '/content/gdrive/MyDrive/'\n","\n","# Add the DinoV2 code directory to the system path for module imports\n","sys.path.append(os.path.join(project_dir, \"code/DinoV2/\"))\n","\n","# Define the runs directory path within the project directory\n","runs_directory = os.path.join(project_dir, 'runs')\n","\n","# Define the data directory path within the project directory\n","data_directory = os.path.join(project_dir, 'data')"],"metadata":{"id":"IiV8zicz5Frq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Some functions\n"],"metadata":{"id":"NciMnHEJ4DaM"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"NaKS4k_iQgKD"},"outputs":[],"source":["class UnetSegmentor(nn.Module):\n","    def __init__(self, n_blocks=4, n_filter=32, num_classes=1, p=0.5):\n","        super(UnetSegmentor, self).__init__()\n","        self.n_blocks = n_blocks\n","        self.p = p\n","        self.input_conv = nn.Conv2d(in_channels=3, out_channels=n_filter, kernel_size=3, padding=1)\n","        self.encoder_convs = nn.ModuleList([self._create_encoder_conv_block(channels=n_filter*2**i, kernel_size=3) for i in range(0,n_blocks-1)])\n","        self.mid_conv = self._create_encoder_conv_block(channels=n_filter*2**(n_blocks-1),  kernel_size=3)\n","        self.decoder_deconvs = nn.ModuleList([nn.ConvTranspose2d(in_channels=n_filter*2**(i+1), out_channels=n_filter*2**i, kernel_size=3, stride=2, padding=1, output_padding=1) for i in reversed(range(n_blocks))])\n","        self.decoder_convs = nn.ModuleList([self._create_decoder_conv_block(channels=n_filter*2**i, kernel_size=3) for i in reversed(range(n_blocks))])\n","        self.seg_conv = nn.Conv2d(in_channels=n_filter, out_channels=num_classes, kernel_size=3, padding=1)\n","\n","    def _create_encoder_conv_block(self, channels, kernel_size):\n","            return nn.Sequential(\n","                nn.Conv2d(channels, channels*2, kernel_size=kernel_size, padding=1),\n","                nn.BatchNorm2d(channels*2),\n","                nn.ReLU(),\n","                nn.Conv2d(channels*2, channels*2, kernel_size=kernel_size, padding=1),\n","                nn.BatchNorm2d(channels*2),\n","                nn.ReLU(),\n","            )\n","\n","    def _create_decoder_conv_block(self, channels, kernel_size):\n","            return nn.Sequential(\n","                nn.Conv2d(channels, channels, kernel_size=kernel_size, padding=1),\n","                nn.BatchNorm2d(channels),\n","                nn.ReLU(),\n","                nn.Conv2d(channels, channels, kernel_size=kernel_size, padding=1),\n","                nn.BatchNorm2d(channels),\n","                nn.ReLU(),\n","            )\n","\n","    def forward(self, x):\n","        feature_list = []\n","        x = self.input_conv(x)\n","        feature_list.append(x)\n","        x = F.max_pool2d(x, kernel_size=2)\n","        x = F.dropout(x, p=self.p)\n","        for i in range(self.n_blocks-1):\n","            x = self.encoder_convs[i](x)\n","            feature_list.append(x)\n","            x = F.max_pool2d(x, kernel_size=2)\n","            x = F.dropout(x, p=self.p)\n","\n","        x = self.mid_conv(x)\n","\n","        for i in range(self.n_blocks):\n","            x = self.decoder_deconvs[i](x)\n","            x = F.dropout(x, p=self.p)\n","            x = self.decoder_convs[i](x+feature_list[::-1][i])\n","\n","        return self.seg_conv(x)\n","\n","def load_segmentation_data(data_dir, device, img_res, num_samples, train_rocks, test_rocks, num_classes=1, val_split=0.8, batch_size=2):\n","    # Initialize the training dataset with specified parameters\n","    train_dataset = EfficientSegmentationDataset(\n","        data_dir, train_rocks, num_samples=num_samples, num_classes=num_classes, img_res=img_res\n","    )\n","\n","    # Initialize the testing dataset with specified parameters (num_samples set to 500 by default)\n","    test_dataset = EfficientSegmentationDataset(\n","        data_dir, test_rocks, num_samples=500, num_classes=num_classes, img_res=img_res\n","    )\n","\n","    pin_memory_device = 'cuda'\n","\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True, pin_memory_device=pin_memory_device)\n","    val_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True, pin_memory_device=pin_memory_device)\n","\n","    return {'train': train_loader, 'val': val_loader, 'num_classes': num_classes}\n","\n","class EfficientSegmentationDataset(VisionDataset):\n","    def __init__(self, data_dir, rock_names, num_classes=3, num_samples=None, crop_size = (224,224), p=0.5, img_res=224, save_dir=None):\n","        super().__init__(data_dir, transforms=None)\n","        print(\"Loading data ...\")\n","        # The stats have been computed on our side. These values represents the mean and stddev pour each rock dataset\n","        self.data_stats = {\n","            \"sample1\" : [\n","                np.array([123.07921846875976]*3)/255.0, np.array([84.04993142526148]*3)/255.0\n","            ],\n","\n","            \"sample2\" : [\n","                np.array([117.92807255795907]*3)/255.0, np.array([80.61479412614699]*3)/255.0\n","            ],\n","\n","            \"sample3\" : [\n","                np.array([119.7933619436969]*3)/255.0, np.array([80.18348841827216]*3)/255.0\n","            ],\n","\n","        }\n","        self.img_data = [np.lib.format.open_memmap(data_dir+f\"/{rock}_img.npy\", dtype=np.uint8, mode='r') for rock in rock_names]\n","        self.mask_data = [np.lib.format.open_memmap(data_dir+f\"/{rock}_mask.npy\", dtype=np.uint8, mode='r') for rock in rock_names]\n","        self.rock_names = rock_names\n","        self.crop_size=crop_size\n","        self.p=p\n","        self.OFFSET = 128\n","        self.IMG_RES = img_res\n","        self.save_dir = save_dir\n","        self.num_classes = num_classes\n","        self.inference_mode = False\n","\n","        if num_samples is None:\n","          self.num_samples = len(self.img_data[0])\n","        else:\n","          self.num_samples = num_samples\n","\n","        self.num_datasets = len(self.img_data)\n","\n","    def infer(self):\n","        self.inference_mode = True\n","\n","    def train(self):\n","        self.inference_mode = False\n","\n","    def get_random_crop_params(self):\n","        h, w = (1014, 976)\n","        th, tw = self.crop_size\n","\n","        if h < th or w < tw:\n","            raise ValueError(f\"Required crop size {(th, tw)} is larger than input image size {(h, w)}\")\n","\n","        if w == tw and h == th:\n","            return 0, 0, h, w\n","\n","        i = torch.randint(0, h - th + 1, size=(1,)).item()\n","        j = torch.randint(0, w - tw + 1, size=(1,)).item()\n","\n","        return i, j, th, tw\n","\n","\n","    def _weights_calc(self, mask, temperature=50.0):\n","        # Calculate the class frequencies\n","        values_to_count = [85, 170, 255]\n","        counts = np.bincount(mask.ravel())[values_to_count]\n","        class_ratio = counts / np.sum(counts)\n","        u_weights = 1/class_ratio\n","        weights = np.nan_to_num(u_weights, posinf=-np.inf)\n","        weights = F.softmax(torch.from_numpy(weights).float()/temperature, dim=-1)\n","        if torch.any(torch.isnan(weights)):\n","            print(weights)\n","            print(class_ratio)\n","            print(u_weights)\n","            raise\n","        return weights\n","\n","    def non_local_means_filter(self, image, h=10, templateWindowSize=7, searchWindowSize=21):\n","        return cv2.fastNlMeansDenoising(image, None, h, templateWindowSize, searchWindowSize)\n","\n","    def __getitem__(self, idx):\n","\n","        try:\n","            i, j, h, w = self.get_random_crop_params()\n","            idx_x = i\n","            idx_y = j\n","            if idx_x < self.OFFSET:\n","                idx_x += self.OFFSET\n","            if idx_y < self.OFFSET:\n","                idx_y += self.OFFSET\n","\n","            dataset_index = idx % self.num_datasets\n","            data_idx = (idx // self.num_datasets)\n","\n","            img = self.img_data[dataset_index][data_idx, idx_x:h+idx_x, idx_y:w+idx_y, :].copy()\n","            mask = self.mask_data[dataset_index][data_idx, idx_x:h+idx_x, idx_y:w+idx_y].copy()\n","\n","            if img is None or mask is None:\n","                raise ValueError(\"Image or mask is None.\")\n","\n","            weights = self._weights_calc(mask)\n","\n","            img = torch.from_numpy(img.transpose((2, 0, 1))).contiguous() / 255.0\n","            mask = torch.from_numpy(mask).contiguous() / 255.0\n","\n","            img = F.interpolate(input=img.unsqueeze(0), size=(self.IMG_RES, self.IMG_RES), mode=\"bicubic\", align_corners=False).squeeze()\n","            mask = F.interpolate(input=mask.unsqueeze(0).unsqueeze(0), size=(self.IMG_RES, self.IMG_RES), mode=\"nearest\").squeeze()\n","\n","            if torch.rand(1) < self.p and not self.inference_mode:\n","                img = torchvision.transforms.functional.hflip(img)\n","                mask = torchvision.transforms.functional.hflip(mask)\n","\n","            if torch.rand(1) < self.p and not self.inference_mode:\n","                img = torchvision.transforms.functional.vflip(img)\n","                mask = torchvision.transforms.functional.vflip(mask)\n","\n","            img_unalt = img\n","\n","            contrast = 0.5 * torch.rand(1)\n","            img = Fv.adjust_contrast(img, 0.75 + contrast)\n","\n","            if not self.inference_mode:\n","                brightness = random.uniform(0.8, 1.2)\n","                contrast = random.uniform(0.8, 1.2)\n","                img = torchvision.transforms.functional.adjust_brightness(img, brightness)\n","                img = torchvision.transforms.functional.adjust_contrast(img, contrast)\n","\n","                gamma = random.uniform(0.5, 1.5)\n","                img = torchvision.transforms.functional.adjust_gamma(img, gamma)\n","\n","            m = self.data_stats[self.rock_names[dataset_index]][0]\n","            s = self.data_stats[self.rock_names[dataset_index]][1]\n","\n","            if self.num_classes > 2:\n","                mask = (mask * self.num_classes).long() - 1\n","\n","            img = torchvision.transforms.functional.normalize(img, m, s).float()\n","            return img, mask, weights, img_unalt\n","\n","        except Exception as e:\n","            print(f\"Error processing index {idx}: {e}\")\n","            # Return a valid default value (e.g., an empty tensor) to avoid returning None\n","            return torch.zeros(3, self.IMG_RES, self.IMG_RES), torch.zeros(self.IMG_RES, self.IMG_RES), torch.zeros(self.IMG_RES, self.IMG_RES), torch.zeros(3, self.IMG_RES, self.IMG_RES)\n","\n","    def __len__(self):\n","        return self.num_datasets * self.num_samples"]},{"cell_type":"markdown","source":["Variable settings"],"metadata":{"id":"7kf0kjn1vYkJ"}},{"cell_type":"code","source":["# Define the name of the folder containining the datasets. All data are in npy format.\n","# The expected data directory structure is as follows:\n","# Datasets\n","# |_Sample1\n","# |  |_img.npy\n","# |  |_mask.npy\n","# |_Sample2\n","# |  |_img.npy\n","# |  |_mask.npy\n","# ...\n","dataset_name = \"Alhammadi\"\n","\n","# Set the device to 'cuda' for GPU usage\n","device = 'cuda'\n","\n","# Define the training and testing rock samples\n","train_rocks = ['sample1', 'sample2']\n","test_rocks = [\"sample3\"]\n","\n","# Set the batch size for data loading\n","batch_size = 15\n","\n","# Set the number of epochs for training\n","epoch_nb = 20\n","\n","# Specify the size of the model (small or large)\n","size_network = \"small\"\n","\n","# Set the image resolution.\n","img_res = 560\n","\n","# Set the number of samples to be used for training.\n","# This number represents the amount of 2D slice that will be randomly selected per dataset (in our case 500*2)\n","num_samples = 500\n","\n","# Using the datasets that carry 3 classes\n","num_classes = 3\n","\n","# Set the learning rate\n","lr=1e-4\n","\n","# set the weight decay\n","weight_decay=5e-4\n","\n","# Get the number of datasets based on the length of training rocks\n","num_dataset = len(train_rocks)\n","\n","# Folder used to save the weights/checkpoints after training and/or read the weights for inference\n","save_directory = runs_directory +'/UNet_'+ f\"{size_network}_{num_samples}_{img_res}/\"\n","\n","# Data loading\n","data_npy = os.path.join(project_dir, \"npy_data\", dataset_name)\n","dataloaders = load_segmentation_data(data_dir=data_npy,\n","                                     device=device,\n","                                     img_res=img_res,\n","                                     num_samples=num_samples,\n","                                     train_rocks=train_rocks,\n","                                     test_rocks=test_rocks,\n","                                     num_classes=num_classes,\n","                                     batch_size=batch_size)"],"metadata":{"id":"ibCNbC_gqpwx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zj_4ZwKLCd4n"},"source":["# **Training**"]},{"cell_type":"markdown","source":["Just run this to get the magic done"],"metadata":{"id":"G_DuggKkHEDv"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"HNH-Z3Vu0q-v"},"outputs":[],"source":["if not os.path.exists(save_directory):\n","\t\tos.makedirs(save_directory)\n","\n","print(save_directory)\n","\n","# Get the number of datasets based on the length of training rocks\n","num_dataset = len(train_rocks)\n","\n","# Define the directory to save the results\n","save_directory = runs_directory +'/UNet_'+ f\"{size_network}_{num_samples}_{img_res}/\"\n","if not os.path.exists(save_directory):\n","    os.makedirs(save_directory)\n","\n","print(save_directory)\n","\n","def plot_learning_curves(loss_dict, jaccard_dict, MODEL_FOLDER):\n","    \"\"\"\n","    Plots the learning curves for loss and IoU over epochs.\n","\n","    Args:\n","        loss_dict (dict): Dictionary containing loss values for training and validation.\n","        jaccard_dict (dict): Dictionary containing IoU values for training and validation.\n","        MODEL_FOLDER (str): Directory to save the plot.\n","    \"\"\"\n","    # Extract epochs and corresponding loss and IoU values\n","    epochs = list(loss_dict['train'].keys())\n","    train_loss_values = [loss_dict['train'][epoch] for epoch in epochs]\n","    val_loss_values = [loss_dict['val'][epoch] for epoch in epochs]\n","    train_jaccard_values = [jaccard_dict['train']['mean_iou'][epoch - 1] for epoch in epochs]\n","    val_jaccard_values = [jaccard_dict['val']['mean_iou'][epoch - 1] for epoch in epochs]\n","\n","    # Create subplots for loss and IoU\n","    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n","    ax0 = axes[0]\n","    ax2 = axes[1]\n","\n","    # Plot loss values\n","    ax0.plot(epochs, train_loss_values, 'b-', label='train')\n","    ax0.plot(epochs, val_loss_values, 'r-', label='val')\n","    ax0.set_title('Loss')\n","    ax0.set_xlabel('Epochs')\n","    ax0.set_ylabel('Loss')\n","\n","    # Plot IoU values\n","    ax2.plot(epochs, train_jaccard_values, 'b-', label='train')\n","    ax2.plot(epochs, val_jaccard_values, 'r-', label='val')\n","    ax2.set_title('IoU')\n","    ax2.set_xlabel('Epochs')\n","    ax2.set_ylabel('%')\n","    ax2.set_ylim(0.1, 1.0)\n","    ax2.legend()\n","\n","    plt.tight_layout()\n","    plt.savefig(os.path.join(save_directory, 'learning_curves.png'), dpi=300)\n","\n","def save_experiment_params(num_samples_train, batch_size, num_dataset, EPOCH_NB, lr, weight_decay, model):\n","    \"\"\"\n","    Saves the experiment parameters and model state dictionary.\n","\n","    Args:\n","        num_samples_train (int): Number of training samples.\n","        batch_size (int): Batch size.\n","        num_dataset (int): Number of datasets.\n","        EPOCH_NB (int): Number of epochs.\n","        lr (float): Learning rate.\n","        weight_decay (float): Weight decay.\n","        model (torch.nn.Module): Trained model.\n","    \"\"\"\n","    # Create folder name based on current date and time\n","    current_time = datetime.now().strftime(\"%d-%m-%Y-%H-%M\")\n","    folder_name = f'UNET-{current_time}'\n","\n","    # Create the directory if it doesn't exist\n","    folder_path = os.path.join(save_directory, folder_name)\n","    os.makedirs(folder_path, exist_ok=True)\n","\n","    # Save the experiment parameters to a text file\n","    params_file_path = os.path.join(folder_path, 'experiment_params.txt')\n","    with open(params_file_path, 'w') as f:\n","        f.write(f'num_samples_train={num_samples_train}\\n')\n","        f.write(f'batch_size={batch_size}\\n')\n","        f.write(f'num_dataset={num_dataset}\\n')\n","        f.write(f'EPOCH_NB={EPOCH_NB}\\n')\n","        f.write(f'lr={lr}\\n')\n","        f.write(f'weight_decay={weight_decay}\\n')\n","\n","    # Save the model state dict\n","    model_file_path = os.path.join(folder_path, 'model_state_dict.pth')\n","    torch.save(model.state_dict(), model_file_path)\n","\n","def save_dicts(loss_dict, jaccard_dict, file_path):\n","    \"\"\"\n","    Saves the loss and IoU dictionaries as PyTorch tensors.\n","\n","    Args:\n","        loss_dict (dict): Dictionary containing loss values for training and validation.\n","        jaccard_dict (dict): Dictionary containing IoU values for training and validation.\n","        file_path (str): Directory to save the tensors.\n","    \"\"\"\n","    # Convert dictionaries to PyTorch tensors\n","    loss_tensor = {\n","        'train': torch.tensor(list(loss_dict['train'].values())),\n","        'val': torch.tensor(list(loss_dict['val'].values()))\n","    }\n","\n","    jaccard_tensor = {\n","        'train': torch.tensor(jaccard_dict['train']['mean_iou']),\n","        'val': torch.tensor(jaccard_dict['val']['mean_iou'])\n","    }\n","\n","    # Save tensors to files\n","    torch.save(loss_tensor, os.path.join(file_path, 'loss_tensor.pt'))\n","    torch.save(jaccard_tensor, os.path.join(file_path, 'iou_tensor.pt'))\n","\n","def train_segmentation_model(model, dataloaders, criterion, optimizer, scheduler, device, epoch_nb=10):\n","    \"\"\"\n","    Trains the segmentation model.\n","\n","    Args:\n","        model (torch.nn.Module): The segmentation model.\n","        dataloaders (dict): Dictionary containing training and validation dataloaders.\n","        criterion (torch.nn.Module): Loss function.\n","        optimizer (torch.optim.Optimizer): Optimizer.\n","        scheduler (torch.optim.lr_scheduler._LRScheduler): Learning rate scheduler.\n","        device (str): Device to run the training on ('cuda' or 'cpu').\n","        epoch_nb (int): Number of epochs to train.\n","\n","    Returns:\n","        torch.nn.Module: Trained model.\n","    \"\"\"\n","    if device == \"cuda\":\n","        scaler = torch.cuda.amp.GradScaler()\n","        import torch.backends.cudnn as cudnn\n","        cudnn.benchmark = True\n","\n","    jaccard = torchmetrics.classification.MulticlassJaccardIndex(num_classes=3, ignore_index=-1).to(device)\n","\n","    print('New model')\n","    epoch_init = 1\n","    loss_dict = {}\n","    metrics_dict = {}\n","    monitored_metrics = [\"mean_iou\"]\n","    for phase in ['train', 'val']:\n","        loss_dict[phase] = {}\n","        metrics_dict[phase] = {}\n","        for m in monitored_metrics:\n","            metrics_dict[phase][m] = []\n","\n","    best_train_iou = 0\n","    best_val_iou = 0\n","    best_val_loss = 100000\n","    for epoch in range(epoch_init, epoch_init+epoch_nb):\n","        print('\\n')\n","        print('-' * 18)\n","        print('--- Epoch {}/{} ---'.format(epoch, epoch_init+epoch_nb-1))\n","\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                is_training = True\n","                model.train()\n","            else:\n","                model.eval()\n","                is_training = False\n","\n","            # Initialize metrics for this phase\n","            running_loss = 0.0  # Accumulate losses over the epoch\n","            running_iou = 0.0\n","            correct = 0\n","            with tqdm(total=len(dataloaders[phase]), unit='batch') as p:\n","\n","                for batch_idx, (inputs, labels, weights, _) in enumerate(dataloaders[phase]):\n","                    inputs = inputs.to(device)\n","                    labels = labels.to(device)\n","                    weights = weights.to(device)\n","                    optimizer.zero_grad()\n","\n","                    batch_weights = torch.mean(weights, dim=0)\n","                    with torch.set_grad_enabled(is_training):\n","                        with torch.autocast(device_type=device, dtype=torch.float16):\n","                            outputs = model(inputs).squeeze()\n","                            loss = F.cross_entropy(outputs, labels.squeeze(), ignore_index=-1, weight=batch_weights, label_smoothing=0.05)\n","                            if is_training:\n","                                if device==\"cuda\":\n","                                    scaler.scale(loss).backward()\n","                                    scaler.step(optimizer)\n","                                    scaler.update()\n","                                else:\n","                                    loss.backward()\n","                                    optimizer.step()\n","                                scheduler.step()\n","\n","                    # Update running loss and correct prediction count\n","                    running_loss += loss.item()\n","\n","                    with torch.no_grad():\n","                        mIoU = jaccard(outputs, labels.squeeze())#mean_iou.compute(predictions=preds, references=labels.squeeze(), num_labels=3, ignore_index=255)\n","                        running_iou += mIoU\n","\n","                    # Update the progress bar\n","                    p.set_postfix({'loss': running_loss/(batch_idx+1),  \"mIoU\" : running_iou/(batch_idx+1)})\n","                    p.update(1)\n","\n","                # Calculate loss, accuracy, and Jaccard Index for this epoch\n","                epoch_loss = running_loss /(batch_idx+1)\n","                epoch_iou = running_iou /(batch_idx+1)\n","                if not is_training:\n","                    if epoch_iou > best_val_iou:\n","                        best_val_iou = epoch_iou\n","                        torch.save(model.state_dict(), save_directory+\"model_best_iou.pth\")\n","\n","                    if epoch_loss < best_val_loss:\n","                        best_val_loss = epoch_loss\n","                        torch.save(model.state_dict(), save_directory+\"model_best_loss.pth\")\n","\n","\n","                loss_dict[phase][epoch] = epoch_loss\n","                metrics_dict[phase][\"mean_iou\"].append(epoch_iou.cpu().item())\n","\n","    # Get the maximum IoU value from the 'val' phase\n","    max_val_iou = max(metrics_dict['val'][\"mean_iou\"])\n","\n","    print(f\"The maximum IoU value in the validation set is: {max_val_iou}\")\n","    save_dicts(loss_dict, metrics_dict, save_directory)\n","\n","    plot_learning_curves(loss_dict, metrics_dict, save_directory)\n","\n","    return model\n","\n","# Set the number of filters based on the size of the network\n","if size_network == \"small\":\n","    n_filters = 32\n","elif size_network == \"large\":\n","    n_filters = 64\n","\n","# Calculate the number of training steps\n","num_training_steps = epoch_nb * len(dataloaders[\"train\"])\n","\n","# Initialize the model\n","model = UnetSegmentor(num_classes=num_classes, n_filter=n_filters)\n","model.to(device)\n","\n","# Define the loss function\n","loss = nn.CrossEntropyLoss()\n","\n","# Define the optimizer\n","optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n","\n","# Define the learning rate scheduler\n","lr_scheduler = get_scheduler(name=\"linear\", optimizer=optimizer, num_warmup_steps=10, num_training_steps=num_training_steps)\n","\n","print(f\"Number of parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n","\n","# Train the model\n","model = train_segmentation_model(model, dataloaders, loss, optimizer, lr_scheduler, device, epoch_nb)\n","\n","# Save the experiment parameters and model state\n","save_experiment_params(num_samples,\n","                       batch_size,\n","                       num_dataset,\n","                       epoch_nb,\n","                       lr,\n","                       weight_decay,\n","                       model)"]},{"cell_type":"markdown","metadata":{"id":"pjAMdiMr_V55"},"source":["# **Inference**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HSIpL64Bax-4"},"outputs":[],"source":["# Initialize the model\n","model = UnetSegmentor(num_classes=num_classes)\n","model.to(device)\n","\n","# Load state dictionary\n","model_name = \"model_best_iou.pth\"\n","checkpoint = torch.load(os.path.join(save_directory, model_name), map_location=torch.device('cpu'))\n","\n","# Load the model's state dictionary\n","model.load_state_dict(checkpoint)\n","\n","# Set the model to evaluation mode\n","model.eval()"]},{"cell_type":"markdown","source":["Run this for a random prediction on the val set"],"metadata":{"id":"feFOnsOV9L-A"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"I5HAr3q0d3L3"},"outputs":[],"source":["# Get a batch of validation data\n","data_iter = iter(dataloaders['val'])\n","data_batch = next(data_iter)\n","\n","# Extract the first image and mask from the batch\n","image_presentation = data_batch[3][0]  # First image for presentation\n","image = data_batch[0][0].unsqueeze(0)  # First image with batch dimension added\n","mask = data_batch[1][0].unsqueeze(0)   # First mask with batch dimension added\n","\n","# Move the model to the specified device (CPU or GPU)\n","model.to(device)\n","\n","# Predict the mask using the model\n","with torch.no_grad():\n","    image = image.to(device)  # Move the image to the specified device\n","    predicted_mask = model(image)  # Get the predicted mask from the model\n","    preds = torch.argmax(predicted_mask, dim=1).cpu()  # Get the class with the highest probability for each pixel\n","\n","def pred_function(image, mask, preds):\n","    \"\"\"\n","    Displays the image, ground truth mask, and predicted mask.\n","\n","    Args:\n","        image (torch.Tensor): The input image.\n","        mask (torch.Tensor): The ground truth mask.\n","        preds (torch.Tensor): The predicted mask.\n","    \"\"\"\n","    # Print the shape and value range of the image and mask\n","    print(f\"Image shape: {image.shape}\")\n","    print(f\"Mask shape: {mask.shape}\")\n","    print(f\"Minimum value of the image: {image.min().item()}\")\n","    print(f\"Maximum value of the image: {image.max().item()}\")\n","    print(f\"Minimum value of the mask: {mask.min().item()}\")\n","    print(f\"Maximum value of the mask: {mask.max().item()}\")\n","\n","    # Create subplots to display the image, mask, and predicted mask\n","    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n","\n","    # Plot the image\n","    image = image.numpy().transpose(1, 2, 0)  # Convert to numpy and transpose for correct display\n","    axes[0].imshow(image)\n","    axes[0].set_title('Image')\n","\n","    # Plot the ground truth mask\n","    mask = mask[0].numpy()  # Convert to numpy\n","    axes[1].imshow(mask)\n","    axes[1].set_title('Mask')\n","\n","    # Plot the predicted mask\n","    preds = preds.squeeze().numpy()  # Convert to numpy and remove extra dimensions\n","    axes[2].imshow(preds)\n","    axes[2].set_title('Predicted Mask')\n","\n","    plt.show()\n","\n","def plot_learning_curves_from_pt(loss_tensor_file, jaccard_tensor_file):\n","    \"\"\"\n","    Plots the learning curves for loss and IoU from saved tensor files.\n","\n","    Args:\n","        loss_tensor_file (str): Path to the file containing loss tensors.\n","        jaccard_tensor_file (str): Path to the file containing IoU tensors.\n","    \"\"\"\n","    # Load tensors from files\n","    loss_tensor = torch.load(loss_tensor_file)\n","    jaccard_tensor = torch.load(jaccard_tensor_file)\n","\n","    # Convert tensors to lists\n","    train_loss_values = loss_tensor['train'].tolist()\n","    val_loss_values = loss_tensor['val'].tolist()\n","    train_jaccard_values = jaccard_tensor['train'].tolist()\n","    val_jaccard_values = jaccard_tensor['val'].tolist()\n","\n","    # Extract epochs\n","    epochs = list(range(1, len(train_loss_values) + 1))\n","\n","    # Plot learning curves\n","    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n","\n","    # Plot loss values\n","    ax0 = axes[0]\n","    ax0.plot(epochs, train_loss_values, 'b-', label='train')\n","    ax0.plot(epochs, val_loss_values, 'r-', label='val')\n","    ax0.set_title('Loss')\n","    ax0.set_xlabel('Epochs')\n","    ax0.set_ylabel('Loss')\n","\n","    # Plot IoU values\n","    ax2 = axes[1]\n","    ax2.plot(epochs, train_jaccard_values, 'b-', label='train')\n","    ax2.plot(epochs, val_jaccard_values, 'r-', label='val')\n","    ax2.set_title('IoU')\n","    ax2.set_xlabel('Epochs')\n","    ax2.set_ylabel('%')\n","    ax2.legend()\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Load the saved tensors\n","loss_tensor = torch.load(os.path.join(save_directory, 'loss_tensor.pt'))\n","jaccard_tensor = torch.load(os.path.join(save_directory, 'iou_tensor.pt'))\n","\n","# Find the largest IoU value for 'val' tensors\n","largest_iou_val = jaccard_tensor['val'].max().item()\n","\n","# Find the smallest loss value for 'val' tensors\n","smallest_loss_val = loss_tensor['val'].min().item()\n","\n","# Print the largest IoU and smallest loss values\n","print(\"Largest IoU value for 'val' tensors:\", largest_iou_val)\n","print(\"Smallest loss value for 'val' tensors:\", smallest_loss_val)\n","\n","\n","# Display the image, ground truth mask, and predicted mask\n","pred_function(image_presentation.cpu(), mask.cpu(), preds.cpu())\n","\n","\n","# Plot the learning curves\n","plot_learning_curves_from_pt(os.path.join(save_directory, 'loss_tensor.pt'),\n","                             os.path.join(save_directory, 'iou_tensor.pt'))"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["Eea7gOXnPViA","zj_4ZwKLCd4n","pjAMdiMr_V55"],"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}