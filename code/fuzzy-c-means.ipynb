{"cells":[{"cell_type":"markdown","source":["#**Libraries / path definition**"],"metadata":{"id":"_p9gsdmELf7m"},"id":"_p9gsdmELf7m"},{"cell_type":"code","source":["!pip install torchmetrics"],"metadata":{"id":"FCL0XcvfZJi8"},"id":"FCL0XcvfZJi8","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import re\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import tifffile\n","from PIL import Image\n","import torch\n","import torch.nn.functional as F\n","import sys\n","import torchmetrics\n","from skimage import io\n","from torchmetrics.classification import MulticlassJaccardIndex\n","import random"],"metadata":{"id":"Gjv_0AwPLoc9"},"id":"Gjv_0AwPLoc9","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the project directory path\n","project_dir = '/content/gdrive/MyDrive/'\n","\n","# Define the name of the folder containining the datasets. All data are in tiff format (or equivalent).\n","# The expected data directory structure is as follows:\n","# Datasets\n","# |_Sample1\n","# |  |_img\n","# |     |_image1.tiff\n","# |     |_image2.tiff\n","# |     |_...\n","# |  |_mask\n","# |     |_mask1.tiff\n","# |     |_mask2.tiff\n","# |     |_...\n","# |  |_...\n","# ...\n","dataset_name = \"some_dataset\"\n","sample_name = \"sample3\"\n","num_classes = 3\n","crop_size = (560, 560)\n","# Arguments for processing the images. Can be modified.\n","# User need to set the fixed_values according to data to be processed and the number of classes\n","args = {\n","    'fixed_values': [85, 170, 255],\n","    'num_bit': 8,\n","    'num_cluster': 3,\n","    'fuzziness': 2,\n","    'epsilon': 0.005,\n","    'max_iteration': 1000,\n","}\n","\n","######\n","\n","# Add the DinoV2 code directory to the system path for module imports\n","sys.path.append(os.path.join(project_dir, \"code/DinoV2/\"))\n","\n","# Define the data directory path within the project directory\n","data_directory = os.path.join(project_dir, 'data')\n","\n","# Define the input directory path to the dataset for segmentation\n","input_directory = os.path.join(data_directory, dataset_name, sample_name)"],"metadata":{"id":"exl8lvEPLk1F"},"id":"exl8lvEPLk1F","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Various functions**\n","\n","\n"],"metadata":{"id":"D-d-5PMrV54v"},"id":"D-d-5PMrV54v"},{"cell_type":"code","source":["class FCM():\n","    def __init__(self, image, fixed_values, image_bit, n_clusters, m, epsilon, max_iter):\n","        \"\"\"\n","        Initializes the FCM (Fuzzy C-Means) clustering instance.\n","\n","        Parameters:\n","            image (np.ndarray): Input grayscale image.\n","            image_bit (int): Bit depth of the image.\n","            n_clusters (int): Number of clusters.\n","            m (float): Fuzziness parameter (>= 1).\n","            epsilon (float): Convergence threshold.\n","            max_iter (int): Maximum number of iterations.\n","        \"\"\"\n","        if np.ndim(image) != 2:\n","            raise Exception(\"<image> needs to be 2D (gray scale image).\")\n","        if n_clusters <= 0 or n_clusters != int(n_clusters):\n","            raise Exception(\"<n_clusters> needs to be positive integer.\")\n","        if m < 1:\n","            raise Exception(\"<m> needs to be >= 1.\")\n","        if epsilon <= 0:\n","            raise Exception(\"<epsilon> needs to be > 0\")\n","\n","        self.image = image\n","        self.image_bit = image_bit\n","        self.n_clusters = n_clusters\n","        self.m = m\n","        self.epsilon = epsilon\n","        self.max_iter = max_iter\n","        self.fixed_values= fixed_values\n","\n","        self.shape = image.shape\n","        self.X = image.flatten().astype('float')\n","        self.numPixels = image.size\n","\n","    def initial_U(self):\n","        \"\"\"\n","        Initializes the membership matrix U with equal membership for all clusters.\n","\n","        Returns:\n","            np.ndarray: The initialized membership matrix.\n","        \"\"\"\n","        U = np.zeros((self.numPixels, self.n_clusters))\n","        idx = np.arange(self.numPixels)\n","        for ii in range(self.n_clusters):\n","            idxii = idx % self.n_clusters == ii\n","            U[idxii, ii] = 1\n","        return U\n","\n","    def update_U(self):\n","        \"\"\"\n","        Updates the membership matrix U based on the current cluster centers C.\n","\n","        Returns:\n","            np.ndarray: The updated membership matrix.\n","        \"\"\"\n","        c_mesh, idx_mesh = np.meshgrid(self.C, self.X)\n","        power = 2. / (self.m - 1)\n","        p1 = abs(idx_mesh - c_mesh) ** power\n","        p2 = np.sum((1. / abs(idx_mesh - c_mesh)) ** power, axis=1)\n","        return 1. / (p1 * p2[:, None])\n","\n","    def update_C(self):\n","        \"\"\"\n","        Updates the cluster centers C based on the current membership matrix U.\n","\n","        Returns:\n","            np.ndarray: The updated cluster centers.\n","        \"\"\"\n","        numerator = np.dot(self.X, self.U ** self.m)\n","        denominator = np.sum(self.U ** self.m, axis=0)\n","        return numerator / denominator\n","\n","    def form_clusters(self):\n","        \"\"\"\n","        Forms clusters by iteratively updating U and C until convergence or maximum iterations.\n","\n","        Sets:\n","            self.U: Updated membership matrix.\n","            self.C: Updated cluster centers.\n","        \"\"\"\n","        d = 100\n","        self.U = self.initial_U()\n","        if self.max_iter != -1:\n","            i = 0\n","            while True:\n","                self.C = self.update_C()\n","                old_u = np.copy(self.U)\n","                self.U = self.update_U()\n","                d = np.sum(abs(self.U - old_u))\n","                if d < self.epsilon or i > self.max_iter:\n","                    break\n","                i += 1\n","        else:\n","            i = 0\n","            while d > self.epsilon:\n","                self.C = self.update_C()\n","                old_u = np.copy(self.U)\n","                self.U = self.update_U()\n","                d = np.sum(abs(self.U - old_u))\n","                if d < self.epsilon or i > self.max_iter:\n","                    break\n","                i += 1\n","        self.segmentImage()\n","\n","    def deFuzzify(self):\n","        \"\"\"\n","        Converts the fuzzy membership matrix U to a crisp classification.\n","\n","        Returns:\n","            np.ndarray: Array of cluster indices for each pixel.\n","        \"\"\"\n","        return np.argmax(self.U, axis=1)\n","\n","    def map_clusters_to_fixed_values(self, centroids, fixed_values):\n","        \"\"\"\n","        Maps cluster indices to fixed intensity values.\n","\n","        Parameters:\n","            centroids (np.ndarray): Array of cluster centers.\n","            fixed_values (list): List of fixed intensity values to map to.\n","\n","        Returns:\n","            dict: Mapping from cluster index to fixed intensity value.\n","        \"\"\"\n","        sorted_indices = np.argsort(centroids)\n","        sorted_fixed_values = sorted(fixed_values)\n","        mapping = {sorted_indices[i]: sorted_fixed_values[i] for i in range(len(sorted_fixed_values))}\n","        return mapping\n","\n","    def segmentImage(self):\n","        \"\"\"\n","        Segments the image by de-fuzzifying the membership matrix and mapping clusters to fixed values.\n","\n","        Returns:\n","            np.ndarray: The segmented image.\n","        \"\"\"\n","        result = self.deFuzzify()\n","        fixed_values = self.fixed_values\n","        mapping = self.map_clusters_to_fixed_values(self.C, fixed_values)\n","        mapped_result = np.vectorize(mapping.get)(result)\n","        self.result = mapped_result.reshape(self.shape).astype('int')\n","        return self.result\n","\n","# Define the Non-Local Means filter function\n","def non_local_means_filter(image, h=10, templateWindowSize=7, searchWindowSize=21):\n","    return cv2.fastNlMeansDenoising(image, None, h, templateWindowSize, searchWindowSize)\n","\n","# Define a function to center crop the image\n","def center_crop(image, crop_size):\n","    height, width = image.shape[:2]\n","    crop_height, crop_width = crop_size\n","    if height < crop_height or width < crop_width:\n","        raise ValueError(\"Crop size must be smaller than the image size\")\n","    top = (height - crop_height) // 2\n","    left = (width - crop_width) // 2\n","    cropped_image = image[top:top + crop_height, left:left + crop_width]\n","    return cropped_image\n","\n","def mapping(target, pred, num_classes):\n","  unique_values_target = np.unique(target)\n","  unique_values_pred = np.unique(pred)\n","\n","  # Check that both sets have the same unique values\n","  if np.array_equal(unique_values_target, unique_values_pred):\n","      list_tmp = list(range(num_classes))\n","      # If both sets are mapped using int ranging from 0 to num_classes\n","      if np.array_equal(unique_values_target, list_tmp):\n","          pass  # continue\n","      else:\n","        # Create a mapping dictionary for cropped_mask\n","        mapping_dict_target = {old_val: new_val for old_val, new_val in zip(unique_values_target, list_tmp)}\n","        # Remap cropped_mask\n","        copy_target = np.copy(target)\n","        for old_val, new_val in mapping_dict_target.items():\n","            target[copy_target == old_val] = new_val\n","\n","        # Create a mapping dictionary for otsu_segmented\n","        mapping_dict_pred = {old_val: new_val for old_val, new_val in zip(unique_values_pred, list_tmp)}\n","\n","        # Remap otsu_segmented\n","        copy_pred = np.copy(pred)\n","        for old_val, new_val in mapping_dict_pred.items():\n","            pred[copy_pred == old_val] = new_val\n","  else:\n","      list_tmp = list(range(num_classes))\n","\n","      # Create a mapping dictionary for cropped_mask\n","      mapping_dict_target = {old_val: new_val for old_val, new_val in zip(unique_values_target, list_tmp)}\n","\n","      # Remap cropped_mask\n","      copy_target = np.copy(target)\n","      for old_val, new_val in mapping_dict_target.items():\n","          target[copy_target == old_val] = new_val\n","\n","      # Create a mapping dictionary for otsu_segmented\n","      mapping_dict_pred = {old_val: new_val for old_val, new_val in zip(unique_values_pred, list_tmp)}\n","\n","      # Remap otsu_segmented\n","      copy_pred = np.copy(pred)\n","      for old_val, new_val in mapping_dict_pred.items():\n","          pred[copy_pred == old_val] = new_val\n","\n","  return target, pred\n","\n","\n","def process_images(input_directory, crop_size, num_classes, args):\n","    image_files = [f for f in os.listdir(os.path.join(input_directory, 'images')) if os.path.isfile(os.path.join(input_directory, 'images', f))]\n","    mask_files = [f for f in os.listdir(os.path.join(input_directory, 'masks')) if os.path.isfile(os.path.join(input_directory, 'masks', f))]\n","    jaccard = torchmetrics.classification.MulticlassJaccardIndex(num_classes=num_classes)\n","\n","    def extract_number(file_name):\n","        match = re.search(r'\\d{4}', file_name)\n","        return int(match.group()) if match else 0\n","\n","    image_files = sorted(image_files, key=extract_number)\n","    mask_files = sorted(mask_files, key=extract_number)\n","\n","    combined = list(zip(image_files, mask_files))\n","\n","    results = []\n","    total_iou = 0\n","    count = 0\n","\n","    for img_file, mask_file in tqdm(combined, desc=\"Loading images and masks\", total=len(image_files)):\n","        img_path = os.path.join(input_directory, 'images', img_file)\n","        mask_path = os.path.join(input_directory, 'masks', mask_file)\n","\n","        img = io.imread(img_path, as_gray=True)\n","        mask = io.imread(mask_path, as_gray=True)\n","\n","        filtered_image = non_local_means_filter(img, h=15, templateWindowSize=7, searchWindowSize=21)\n","\n","        # Apply FCM clustering to the filtered image\n","        cluster = FCM(filtered_image, fixed_values=args['fixed_values'], image_bit=args['num_bit'], n_clusters=args['num_cluster'], m=args['fuzziness'], epsilon=args['epsilon'], max_iter=args['max_iteration'])\n","        cluster.form_clusters()\n","        fcm_segmented = cluster.result\n","\n","        cropped_scanner = center_crop(img, crop_size)\n","        cropped_pred = center_crop(fcm_segmented, crop_size)\n","        cropped_mask = center_crop(mask, crop_size)\n","\n","        cropped_mask, cropped_pred = mapping(cropped_mask, cropped_pred, num_classes)\n","\n","        # Convert to tensors with uint8 data type\n","        ground_truth_mask_tensor = torch.tensor(cropped_mask, dtype=torch.uint8)\n","        fcm_mask_tensor = torch.tensor(cropped_pred, dtype=torch.uint8)\n","\n","        # Add batch dimension\n","        ground_truth_mask_tensor = ground_truth_mask_tensor.unsqueeze(0)\n","        fcm_mask_tensor = fcm_mask_tensor.unsqueeze(0)\n","\n","        try:\n","            mIoU = jaccard(fcm_mask_tensor, ground_truth_mask_tensor).item()\n","        except Exception as e:\n","            print(f\"Error calculating mIoU: {e}\")\n","            continue\n","\n","        total_iou += mIoU\n","        count += 1\n","\n","        results.append((cropped_scanner, cropped_mask, cropped_pred))\n","\n","    if count > 0:\n","        average_iou = total_iou / count\n","    else:\n","        average_iou = 0\n","        print(\"No valid image-mask pairs processed.\")\n","\n","    return average_iou, results\n","\n","def display_random_set(image_mask_pred_list):\n","    random_set = random.choice(image_mask_pred_list)\n","    img, ground_truth_mask, pred_mask = random_set\n","    fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n","    ax[0].imshow(img, cmap='gray')\n","    ax[0].set_title('Image')\n","    ax[1].imshow(ground_truth_mask, cmap='gray')\n","    ax[1].set_title('Ground Truth Mask')\n","    ax[2].imshow(pred_mask, cmap='gray')\n","    ax[2].set_title('FCM segmented')\n","    plt.show()"],"metadata":{"id":"ayFXUJ9eCTl3"},"id":"ayFXUJ9eCTl3","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Segmentation**"],"metadata":{"id":"3wsNAJI5WGE1"},"id":"3wsNAJI5WGE1"},{"cell_type":"code","source":["average_iou, results = process_images(input_directory, crop_size, num_classes, args)\n","print(f\"Average IoU: {average_iou:.4f}\")"],"metadata":{"id":"w6_Q3plvEhZo"},"id":"w6_Q3plvEhZo","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Display**"],"metadata":{"id":"JPmVm60XWMMN"},"id":"JPmVm60XWMMN"},{"cell_type":"code","source":["display_random_set(results)"],"metadata":{"id":"pqnhc9JfnOI5"},"id":"pqnhc9JfnOI5","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[],"collapsed_sections":["_p9gsdmELf7m","D-d-5PMrV54v","3wsNAJI5WGE1","JPmVm60XWMMN"]}},"nbformat":4,"nbformat_minor":5}