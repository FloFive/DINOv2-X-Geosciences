{"cells":[{"cell_type":"markdown","source":["#**Libraries / path definition / various functions**"],"metadata":{"id":"og5PE7lcFi-3"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"zSh_V3i4cKzm"},"outputs":[],"source":["!pip install torchmetrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fyaou0fQ4rW9"},"outputs":[],"source":["import cv2\n","import numpy as np\n","import math\n","import sys\n","import os\n","from skimage.filters import threshold_multiotsu\n","import random\n","import matplotlib.pyplot as plt\n","import re\n","from PIL import Image\n","from tqdm import tqdm\n","from skimage import img_as_ubyte, io\n","import torch\n","import torch.nn.functional as F\n","import torchmetrics\n","from torchmetrics.classification import MulticlassJaccardIndex"]},{"cell_type":"code","source":["# Define the project directory path\n","project_dir = '/content/gdrive/MyDrive/'\n","\n","# Define the name of the folder containining the datasets. All data are in tiff format (or equivalent).\n","# The expected data directory structure is as follows:\n","# Datasets\n","# |_Sample1\n","# |  |_img\n","# |     |_image1.tiff\n","# |     |_image2.tiff\n","# |     |_...\n","# |  |_mask\n","# |     |_mask1.tiff\n","# |     |_mask2.tiff\n","# |     |_...\n","# |  |_...\n","# ...\n","dataset_name = \"some_dataset\"\n","sample_name = \"sample3\"\n","num_classes = 3\n","crop_size = (560, 560)\n","\n","######\n","\n","# Add the DinoV2 code directory to the system path for module imports\n","sys.path.append(os.path.join(project_dir, \"code/DinoV2/\"))\n","\n","# Define the data directory path within the project directory\n","data_directory = os.path.join(project_dir, 'data')\n","\n","# Define the input directory path to the dataset for segmentation\n","input_directory = os.path.join(data_directory, dataset_name, sample_name)"],"metadata":{"id":"Yy6Fy_tpzeR_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Various functions**\n"],"metadata":{"id":"CCBZp2CBFlWy"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ghYsBCuZEuYT"},"outputs":[],"source":["# Define the Non-Local Means filter function\n","def non_local_means_filter(image, h=10, templateWindowSize=7, searchWindowSize=21):\n","    return cv2.fastNlMeansDenoising(image, None, h, templateWindowSize, searchWindowSize)\n","\n","# Define the Otsu multi-thresholding function\n","def otsu_multi(image, num_classes):\n","    thresholds = threshold_multiotsu(image, classes=num_classes)\n","    regions = np.digitize(image, bins=thresholds)\n","    return regions\n","\n","# Define a function to center crop the image\n","def center_crop(image, crop_size):\n","    height, width = image.shape[:2]\n","    crop_height, crop_width = crop_size\n","    if height < crop_height or width < crop_width:\n","        raise ValueError(\"Crop size must be smaller than the image size\")\n","    top = (height - crop_height) // 2\n","    left = (width - crop_width) // 2\n","    cropped_image = image[top:top + crop_height, left:left + crop_width]\n","    return cropped_image\n","\n","def remap_values(array, unique_values, target_values):\n","    mapping_dict = {old_val: new_val for old_val, new_val in zip(unique_values, target_values)}\n","    remapped_array = np.copy(array)\n","    for old_val, new_val in mapping_dict.items():\n","        remapped_array[array == old_val] = new_val\n","    return remapped_array\n","\n","def mapping(target, pred, num_classes):\n","    unique_values_target = np.unique(target)\n","    unique_values_pred = np.unique(pred)\n","\n","    # Desired unique values after remapping\n","    target_values = np.arange(num_classes)\n","\n","    if not np.array_equal(unique_values_target, target_values):\n","        target = remap_values(target, unique_values_target, target_values)\n","\n","    if not np.array_equal(unique_values_pred, target_values):\n","        pred = remap_values(pred, unique_values_pred, target_values)\n","\n","    return target, pred\n","\n","\n","def process_images(input_directory, crop_size, num_classes):\n","    image_files = [f for f in os.listdir(os.path.join(input_directory, 'images')) if os.path.isfile(os.path.join(input_directory, 'images', f))]\n","    mask_files = [f for f in os.listdir(os.path.join(input_directory, 'masks')) if os.path.isfile(os.path.join(input_directory, 'masks', f))]\n","    jaccard = torchmetrics.classification.MulticlassJaccardIndex(num_classes=num_classes)\n","\n","    def extract_number(file_name):\n","        match = re.search(r'\\d{4}', file_name)\n","        return int(match.group()) if match else 0\n","\n","    image_files = sorted(image_files, key=extract_number)\n","    mask_files = sorted(mask_files, key=extract_number)\n","    combined = list(zip(image_files, mask_files))\n","\n","    results = []\n","    list_iou = []\n","    total_iou = 0\n","    count = 0\n","\n","    for img_file, mask_file in tqdm(combined, desc=\"Loading images and masks\", total=len(image_files)):\n","        img_path = os.path.join(input_directory, 'images', img_file)\n","        mask_path = os.path.join(input_directory, 'masks', mask_file)\n","\n","        img = io.imread(img_path, as_gray=True)\n","        mask = io.imread(mask_path, as_gray=True)\n","\n","        filtered_image = non_local_means_filter(img, h=15, templateWindowSize=7, searchWindowSize=21)\n","\n","        otsu_segmented = otsu_multi(filtered_image, num_classes)\n","\n","        cropped_scanner = center_crop(img, crop_size)\n","        cropped_pred = center_crop(otsu_segmented, crop_size)\n","        cropped_mask = center_crop(mask, crop_size)\n","\n","        cropped_mask, cropped_pred = mapping(cropped_mask, cropped_pred, num_classes)\n","\n","        # Convert to tensors with uint8 data type\n","        ground_truth_mask_tensor = torch.tensor(cropped_mask, dtype=torch.uint8)\n","        otsu_mask_tensor = torch.tensor(cropped_pred, dtype=torch.uint8)\n","\n","        # Add batch dimension\n","        ground_truth_mask_tensor = ground_truth_mask_tensor.unsqueeze(0)  # Shape: [1, height, width]\n","        otsu_mask_tensor = otsu_mask_tensor.unsqueeze(0)  # Shape: [1, height, width]\n","\n","        try:\n","            mIoU = jaccard(otsu_mask_tensor, ground_truth_mask_tensor).item()\n","        except Exception as e:\n","            print(f\"Error calculating mIoU: {e}\")\n","            continue\n","\n","        list_iou.append(mIoU)\n","\n","        total_iou += mIoU\n","        count += 1\n","\n","        results.append((cropped_scanner, cropped_mask, cropped_pred))\n","\n","    if count > 0:\n","        average_iou = total_iou / count\n","    else:\n","        average_iou = 0\n","        print(\"No valid image-mask pairs processed.\")\n","\n","    return average_iou, results, list_iou\n","\n","def display_random_set(image_mask_pred_list):\n","    random_index = random.randint(0, len(image_mask_pred_list) - 1)\n","    random_set = image_mask_pred_list[random_index]\n","    img, ground_truth_mask, pred_mask = random_set\n","    fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n","    ax[0].imshow(img, cmap='gray')\n","    ax[0].set_title('Image' + str(random_index))\n","    ax[1].imshow(ground_truth_mask, cmap='gray')\n","    ax[1].set_title('Ground Truth Mask')\n","    ax[2].imshow(pred_mask, cmap='gray')\n","    ax[2].set_title('Otsu segmented')\n","    plt.show()"]},{"cell_type":"markdown","source":["# **Segmentation**"],"metadata":{"id":"lp3e_9FUFzII"}},{"cell_type":"code","source":["average_iou, results, iou = process_images(input_directory, crop_size, num_classes)\n","print(\"Average IoU:\", average_iou)"],"metadata":{"id":"ASSLKGPWE89r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Display**"],"metadata":{"id":"vW-qyp5nF08l"}},{"cell_type":"code","source":["display_random_set(results)"],"metadata":{"id":"oJEtwucDBdxE"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"machine_shape":"hm","collapsed_sections":["og5PE7lcFi-3","CCBZp2CBFlWy","lp3e_9FUFzII","vW-qyp5nF08l"],"authorship_tag":"ABX9TyOm53WkAUbjlf7BWsPA7qky"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}