{"cells":[{"cell_type":"markdown","source":["#**Libraries / path definition / various functions**"],"metadata":{"id":"PjWCpg_4qBCg"}},{"cell_type":"code","source":["!pip install torchmetrics"],"metadata":{"id":"_l6PLbPoeJbU"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WLmVQWtSCaRq"},"outputs":[],"source":["import cv2\n","import sys\n","import joblib\n","import numpy as np\n","from skimage import io, feature\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.utils import shuffle\n","import torch\n","import torchmetrics\n","from PIL import Image\n","from tqdm import tqdm\n","import os\n","import re\n","from functools import partial\n","import torch\n","import torchmetrics\n","from torchmetrics import JaccardIndex\n","import random\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","source":["# Define the project directory path\n","project_dir = '/content/gdrive/MyDrive/'\n","\n","# Add the DinoV2 code directory to the system path for module imports\n","sys.path.append(os.path.join(project_dir, \"code/DinoV2/\"))\n","\n","# Define the runs directory path within the project directory\n","runs_directory = os.path.join(project_dir, 'runs')\n","\n","# Define the data directory path within the project directory\n","data_directory = os.path.join(project_dir, 'data')"],"metadata":{"id":"jY5I41SSpy4B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# The expected data directory structure is as follows:\n","# Datasets\n","# |_Sample1\n","# |  |_img\n","# |     |_image1.tiff\n","# |     |_image2.tiff\n","# |     |_...\n","# |  |_mask\n","# |     |_mask1.tiff\n","# |     |_mask2.tiff\n","# |     |_...\n","# |  |_...\n","# ...\n","\n","# Set the input directories for the training sets (training on two rock sets)\n","image_dir1 = data_directory + '/Alhammadi/sample1/images'\n","mask_dir1 = data_directory + '/Alhammadi/sample1/masks'\n","image_dir2 = data_directory + '/Alhammadi/sample2/images'\n","mask_dir2 = data_directory + '/Alhammadi/sample2/masks'\n","\n","# Se the directory for inference (predicting on one rock set)\n","inference_directory = data_directory + '/Alhammadi/sample3/'\n","\n","# Define the number of samples to be used for training or processing\n","num_samples = 1000\n","\n","# Define the size to which images will be cropped. Larger crop will cost more RAM\n","crop_size = (100, 100)\n","\n","# Create the directory path where the model will be saved, incorporating the number of samples and crop size\n","save_directory = runs_directory + '/RF_' + f\"{num_samples}_{crop_size[0]}/\"\n","\n","# Define a mapping from pixel values to class labels. Adapt accordingly\n","mapping = {85: 0, 170: 1, 255: 2}\n","\n","# Define the number of classes in the segmentation task\n","num_classes = 3"],"metadata":{"id":"UQ3DePpLNOrF"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4z-0NIOTR3Wv"},"outputs":[],"source":["def non_local_means_filter(image, h=10, templateWindowSize=7, searchWindowSize=21):\n","    \"\"\"\n","    Apply Non-Local Means Denoising filter to an image.\n","\n","    Parameters:\n","        image (ndarray): Input image.\n","        h (int): Parameter regulating filter strength.\n","        templateWindowSize (int): Size in pixels of the template patch.\n","        searchWindowSize (int): Size in pixels of the window used to compute weighted average.\n","\n","    Returns:\n","        ndarray: Denoised image.\n","    \"\"\"\n","    return cv2.fastNlMeansDenoising(image, None, h, templateWindowSize, searchWindowSize)\n","\n","def load_images_and_masks(image_dirs, mask_dirs, limit=None, crop_size=None):\n","    \"\"\"\n","    Load images and corresponding masks from directories.\n","\n","    Parameters:\n","        image_dirs (list): List of directories containing images.\n","        mask_dirs (list): List of directories containing masks.\n","        limit (int, optional): Limit on the number of images and masks to load.\n","        crop_size (tuple, optional): Size to which images and masks should be cropped.\n","\n","    Returns:\n","        tuple: Lists of images and masks.\n","    \"\"\"\n","    assert len(image_dirs) == len(mask_dirs), \"The number of image directories and mask directories must be the same\"\n","\n","    all_image_files = []\n","    all_mask_files = []\n","\n","    for image_dir, mask_dir in zip(image_dirs, mask_dirs):\n","        image_files = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]\n","        mask_files = [os.path.join(mask_dir, f) for f in os.listdir(mask_dir) if os.path.isfile(os.path.join(mask_dir, f))]\n","\n","        # Define a function to extract the number from the file name\n","        def extract_number(file_name):\n","            match = re.search(r'\\d{4}', file_name)\n","            return int(match.group()) if match else 0\n","\n","        # Sort the image and mask files based on the number in their names\n","        image_files = sorted(image_files, key=extract_number)\n","        mask_files = sorted(mask_files, key=extract_number)\n","\n","        # Shuffle the combined list of image and mask pairs\n","        combined = list(zip(image_files, mask_files))\n","        random.shuffle(combined)\n","        image_files, mask_files = zip(*combined)\n","\n","        # Limit files from each directory if a limit is specified\n","        if limit is not None:\n","            half_limit = limit // len(image_dirs)\n","            image_files = image_files[:half_limit]\n","            mask_files = mask_files[:half_limit]\n","\n","        all_image_files.extend(image_files)\n","        all_mask_files.extend(mask_files)\n","\n","    # Shuffle the combined list of image and mask pairs\n","    combined = list(zip(all_image_files, all_mask_files))\n","    random.shuffle(combined)\n","    all_image_files, all_mask_files = zip(*combined)\n","\n","    images = []\n","    masks = []\n","\n","    for img_path, mask_path in tqdm(zip(all_image_files, all_mask_files), desc=\"Loading images and masks\", total=len(all_image_files)):\n","        img = io.imread(img_path, as_gray=True)\n","        mask = io.imread(mask_path, as_gray=True)\n","\n","        if crop_size is not None:\n","            img = center_crop(img, crop_size)\n","            mask = center_crop(mask, crop_size)\n","\n","        img = non_local_means_filter(img, h=15, templateWindowSize=7, searchWindowSize=21)\n","\n","        images.append(img)\n","        masks.append(mask)\n","\n","    return images, masks\n","\n","def center_crop(image, crop_size):\n","    \"\"\"\n","    Crop the center of an image.\n","\n","    Parameters:\n","        image (ndarray): Input image.\n","        crop_size (tuple): Size to which the image should be cropped.\n","\n","    Returns:\n","        ndarray: Cropped image.\n","    \"\"\"\n","    height, width = image.shape[:2]\n","    crop_height, crop_width = crop_size\n","\n","    if height < crop_height or width < crop_width:\n","        raise ValueError(\"Crop size must be smaller than the image size\")\n","\n","    top = (height - crop_height) // 2\n","    left = (width - crop_width) // 2\n","\n","    cropped_image = image[top:top + crop_height, left:left + crop_width]\n","\n","    return cropped_image\n","\n","def train_segmenter(features, masks):\n","    \"\"\"\n","    Train a Random Forest classifier for image segmentation.\n","\n","    Parameters:\n","        features (list): List of feature arrays.\n","        masks (list): List of mask arrays.\n","\n","    Returns:\n","        RandomForestClassifier: Trained classifier.\n","    \"\"\"\n","    features = np.array(features)\n","    X = features.reshape(-1, features.shape[-1])\n","    masks = np.array(masks)\n","    y = masks.reshape(-1)\n","    X, y = shuffle(X, y, random_state=0)\n","\n","    clf = RandomForestClassifier(\n","        n_estimators=150,\n","        n_jobs=-1,\n","        bootstrap=True,\n","        min_samples_leaf=1,\n","        min_samples_split=2,\n","        criterion='entropy',\n","        max_features=None,\n","        max_depth=15,\n","        max_samples=0.1\n","    )\n","\n","    clf.fit(X, y)\n","\n","    return clf\n","\n","def extract_features(images, sigma_min=1, sigma_max=16):\n","    \"\"\"\n","    Extract multiscale basic features from a list of images.\n","\n","    Parameters:\n","        images (list): List of images.\n","        sigma_min (int): Minimum sigma value for feature extraction.\n","        sigma_max (int): Maximum sigma value for feature extraction.\n","\n","    Returns:\n","        list: List of feature arrays.\n","    \"\"\"\n","    features_func = partial(\n","        feature.multiscale_basic_features,\n","        intensity=True,\n","        edges=False,\n","        texture=True,\n","        sigma_min=sigma_min,\n","        sigma_max=sigma_max,\n","        channel_axis=None  # Explicitly set channel_axis to None for grayscale images\n","    )\n","\n","    features = []\n","    for img in tqdm(images, desc='Extracting features'):\n","        img_features = features_func(img)\n","        # Reshape the features to flatten them\n","        flattened_features = img_features.reshape(-1, img_features.shape[-1])\n","        features.append(flattened_features)\n","\n","    return features\n","\n","def extract_features_single_image(img, sigma_min=1, sigma_max=16):\n","    \"\"\"\n","    Extract multiscale basic features from a single image.\n","\n","    Parameters:\n","        img (ndarray): Input image.\n","        sigma_min (int): Minimum sigma value for feature extraction.\n","        sigma_max (int): Maximum sigma value for feature extraction.\n","\n","    Returns:\n","        ndarray: Flattened feature array.\n","    \"\"\"\n","    features_func = partial(\n","        feature.multiscale_basic_features,\n","        intensity=True,\n","        edges=False,\n","        texture=True,\n","        sigma_min=sigma_min,\n","        sigma_max=sigma_max,\n","        channel_axis=None  # Explicitly set channel_axis to None for grayscale images\n","    )\n","\n","    img_features = features_func(img)\n","    # Reshape the features to flatten them\n","    flattened_features = img_features.reshape(-1, img_features.shape[-1])\n","    return flattened_features\n","\n","def segment_image(img, clf):\n","    \"\"\"\n","    Segment an image using a trained classifier.\n","\n","    Parameters:\n","        img (ndarray): Input image.\n","        clf (RandomForestClassifier): Trained classifier.\n","\n","    Returns:\n","        ndarray: Segmented image.\n","    \"\"\"\n","    features = extract_features_single_image(img)\n","    features = np.vstack(features)\n","    segmented_flat = clf.predict(features)\n","    segmented_image = segmented_flat.reshape(img.shape)\n","    return segmented_image\n","\n","def process_images(input_directory, crop_size, clf, mapping, num_classes):\n","    \"\"\"\n","    Process images and calculate metrics.\n","\n","    Parameters:\n","        input_directory (str): Directory containing images and masks.\n","        crop_size (int): Size to which images and masks should be cropped.\n","        clf (RandomForestClassifier): Trained classifier.\n","        mapping (dict): Mapping of intensity values to class indices.\n","        num_classes (int): Number of classes.\n","\n","    Returns:\n","        tuple: Average IoU and list of tuples (image, ground truth mask, predicted mask).\n","    \"\"\"\n","    jaccard = torchmetrics.classification.MulticlassJaccardIndex(num_classes=num_classes)\n","\n","    image_dir = os.path.join(input_directory, 'images')\n","    mask_dir = os.path.join(input_directory, 'masks')\n","\n","    image_files = [f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]\n","    mask_files = [f for f in os.listdir(mask_dir) if os.path.isfile(os.path.join(mask_dir, f))]\n","\n","    # Define a function to extract the number from the file name\n","    def extract_number(file_name):\n","        match = re.search(r'\\d{4}', file_name)\n","        return int(match.group()) if match else 0\n","\n","    # Sort the image and mask files based on the number in their names\n","    image_files = sorted(image_files, key=extract_number)\n","    mask_files = sorted(mask_files, key=extract_number)\n","\n","    list_segmented_img = []\n","    image_mask_pred_list = []\n","\n","    for image_file in tqdm(image_files, desc=\"Processing images\"):\n","        img_path = os.path.join(image_dir, image_file)\n","        img = io.imread(img_path, as_gray=True)\n","        img = center_crop(img, crop_size)\n","        img = non_local_means_filter(img, h=15, templateWindowSize=7, searchWindowSize=21)\n","\n","        segmented_img = segment_image(img, clf)\n","        list_segmented_img.append((img, segmented_img))\n","\n","    # Initialize total IoU and count\n","    total_iou = 0\n","    count = 0\n","\n","    # Process each mask file\n","    for i, mask_file in enumerate(tqdm(mask_files, desc=\"Calculating metrics\")):\n","        # Load the ground truth mask and the segmented mask\n","        mask_path = os.path.join(mask_dir, mask_file)\n","        ground_truth_mask = np.array(Image.open(mask_path).convert('L'))\n","        img, pred_mask = list_segmented_img[i]\n","\n","        # Crop the center of the images\n","        ground_truth_mask = center_crop(ground_truth_mask, crop_size)\n","\n","        # Convert to PyTorch tensors\n","        ground_truth_mask_tensor = torch.tensor(ground_truth_mask, dtype=torch.int64)\n","        pred_mask_tensor = torch.tensor(pred_mask, dtype=torch.int64)\n","\n","        # Apply the mapping to the tensors\n","        ground_truth_mask_tensor = ground_truth_mask_tensor.apply_(lambda x: mapping[x])\n","        pred_mask_tensor = pred_mask_tensor.apply_(lambda x: mapping[x])\n","\n","        # Ensure the tensors have the same shape\n","        if ground_truth_mask_tensor.shape != pred_mask_tensor.shape:\n","            print(f\"Skipping image {image_file} due to shape mismatch.\")\n","            continue\n","\n","        # Calculate IoU using torchmetrics\n","        mIoU = jaccard(pred_mask_tensor, ground_truth_mask_tensor).item()\n","\n","        # Update total IoU and count\n","        total_iou += mIoU\n","        count += 1\n","\n","        # Append the tuple (image, mask, prediction) to the list\n","        image_mask_pred_list.append((img, ground_truth_mask, pred_mask))\n","\n","    # Calculate average IoU\n","    average_iou = total_iou / count\n","\n","    return average_iou, image_mask_pred_list\n","\n","def display_random_set(image_mask_pred_list):\n","    # Select a random tuple from the list\n","    random_set = random.choice(image_mask_pred_list)\n","\n","    # Unpack the tuple\n","    img, ground_truth_mask, pred_mask = random_set\n","\n","    # Display the images\n","    fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n","    ax[0].imshow(img, cmap='gray')\n","    ax[0].set_title('Image')\n","    ax[1].imshow(ground_truth_mask, cmap='gray')\n","    ax[1].set_title('Ground Truth Mask')\n","    ax[2].imshow(pred_mask, cmap='gray')\n","    ax[2].set_title('Prediction Mask')\n","    plt.show()"]},{"cell_type":"markdown","source":["# **Training**"],"metadata":{"id":"_LHcNU24nky3"}},{"cell_type":"code","source":["# Load images and masks from the specified directories and process them\n","images, masks = load_images_and_masks([image_dir1, image_dir2], [mask_dir1, mask_dir2], num_samples, crop_size)\n","\n","# Extract features from the loaded images\n","features = extract_features(images)\n","\n","# Train the segmenter model using the extracted features and corresponding masks\n","clf = train_segmenter(features, masks)\n","\n","# Check if the save directory exists, if not, create it\n","if not os.path.exists(save_directory):\n","    os.makedirs(save_directory)\n","\n","# Save the trained classifier to the specified directory with a filename that includes the number of samples\n","joblib.dump(clf, save_directory + 'clf_' + str(num_samples) + '.pkl')"],"metadata":{"id":"hgLBmrxSWi3f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a63kXZ7umxV7"},"source":["# **Inference**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IHkEUqcJjXj5"},"outputs":[],"source":["# Load the trained classifier from the specified directory\n","clf = joblib.load(save_directory + 'clf_' + str(num_samples) + '.pkl')\n","\n","# Process images using the loaded classifier to compute the Intersection over Union (IoU) and generate a list of processed images\n","iou, list_img = process_images(inference_directory, crop_size, clf, mapping, num_classes)\n","\n","# Print the average IoU to evaluate the performance of the segmentation\n","print(\"average iou = \" + str(iou))"]},{"cell_type":"markdown","source":["# **Display**"],"metadata":{"id":"2MZ42H-7nrVG"}},{"cell_type":"code","source":["display_random_set(list_img)"],"metadata":{"id":"XfcnmkQwZeGD"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[],"collapsed_sections":["_LHcNU24nky3","a63kXZ7umxV7","2MZ42H-7nrVG"],"authorship_tag":"ABX9TyPJFNvExn7i+9Fgtc1jFict"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}